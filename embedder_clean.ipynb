{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shred-code/vedas-rag-chatbot/blob/main/embedder_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3Zz1hK8szh",
        "outputId": "7b6b3cc7-bd69-40bc-850a-0ef620e20004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8IqItvv85nI",
        "outputId": "e36a7676-c603-4677-bb81-c61ebc3399cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc6G4JF19lpy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/vedas-rag/chunks/rigveda_book1.json\"\n",
        "with open(input_path, \"r\") as f:\n",
        "    hymns = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYuXC-x39zgK"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "\n",
        "for hymn in hymns:\n",
        "    # embed\n",
        "    content = f\"{hymn['title']}\\n\" + \" \".join(hymn[\"verses\"])\n",
        "    texts.append(content)\n",
        "\n",
        "    # Metadata to store alongside\n",
        "    metadatas.append({\n",
        "        \"id\": hymn[\"id\"],\n",
        "        \"veda\": hymn[\"veda\"],\n",
        "        \"book\": hymn[\"book\"],\n",
        "        \"deity\": hymn[\"deity\"],\n",
        "        \"title\": hymn[\"title\"]\n",
        "    })\n",
        "\n",
        "    # ID\n",
        "    ids.append(hymn[\"id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "80cc701bc5eb4ac9a92381f21b88254c",
            "c194cbbc21104cd3844dd5d0a884f2f2",
            "0739fa04102d429ea74fdc1bf84934c4",
            "555ffe905ddd452793a9df35190c000e",
            "58dcf99479264ed5b303bbc7c7e937e3",
            "d44f0a3e7e924aefbf0009271b511799",
            "f081fde92e1f42d4a9854914f298d8d8",
            "3a6df1efd2754634bd0daebb5701d87a",
            "d09c05dd51d046f5893982751e38fb48",
            "5dc4d4721a914e558154a78ba79bfced",
            "6d5617f56ebd47f19e9e6984f0437542",
            "6c7742bbb2024b70bd6cd93c74ddb698",
            "c37f45bc8bc645c9a8bed809837c1276",
            "1c15f68585974720aed865a778e599bd",
            "de3bef0eaf8d447c91d38b98a12808c2",
            "e3078d85c04e4eba971c8531ea20c105",
            "8f0fe9b6f7194bc68231f0e8a2808cb7",
            "58cbeb6fa50640169e99687922ad6b76",
            "cec1192292124e01915bfc083d23312f",
            "9aae5ff5eaaf4fcea3551b0df54fb84b",
            "449d1129acac4ff694139fbaff5dcbb2",
            "5fc4f2d9bf3c4a0ea7fffebf2ff8c591",
            "006ff79eaec7426d98ce092dacf8c075",
            "4efba59234cb4435b9d7ce96407d28ae",
            "79f7ef27fdb3407db417ae0f90f2a25b",
            "459c06a8421848839416f73fe76fedde",
            "cfdfdb1f56764093923c88c4d2c75e00",
            "cc052142eca34bed9ed6afd75b6f1826",
            "e0658eb073eb42798dbe1a4eaaed2245",
            "2ddea77952b64fabb234202b32829a85",
            "bfb43d9cd3534903b13a19ce4da720ec",
            "ae877fff62854e898fc9efd96693211d",
            "70a9e0ba6623469bb922e73c664a590e",
            "88d1ac44a85b423dbe270d73fe645194",
            "0b463b7e87184597a8e1a1b0920458b5",
            "6b5fb1e169ca4ac68024d264507cde12",
            "14ee8be7b73a4dab981f3a21f0d5c79a",
            "96676dad94df47499b2ef5354582bcf9",
            "1427b1bd69c64edbb9cec2c885522a3a",
            "d5b5b1ad2cb9447cb776c8628e6c0901",
            "c81d4a255bf141f7a49238567a87843f",
            "381cb2d201d34fe3bc9bda4bee927fd5",
            "0d66d08682c54abd96a06f4ea748ef12",
            "1e54e99b59114aa8840764441ffa1417",
            "d521069967e345aeb003144142a45801",
            "b1ade43bb5aa4c8285aa73f144fecd8b",
            "d10fe09a47f0493ab764d94943313dbc",
            "af03a0f8f0814e0db7f2feca20c8a5c3",
            "ccfea15f2df54488af380f757e73ed04",
            "d30d54a9d67d4485922df37117749bb0",
            "d88ea976f0a74589b375b788680eb97a",
            "8707b6d989604c128236793f19ac0e09",
            "fb5ddc3582af45ad812b851106d4be92",
            "546a7b6d98aa41d3905e640fcd8d7eb9",
            "a8455c30a2a541beb9fd9ced3516657c",
            "89c65cd249c9418092e101ce349d2379",
            "e18b84e18df34b60817d0be9e2fb7c63",
            "b2a8f28ec98546d5a056e9e3c4136a28",
            "48b0ef491a814a578dfc8226300bdb8c",
            "07cbe0add5374f93be43b5fd9d9fbf74",
            "357b20a8616e4d4f83506c25c8769da4",
            "a087faad6d554e1ab08a927560b73b29",
            "c6491bf2194648ce9444744489bc502c",
            "fc4a385874a14d708ccf37a61501ddad",
            "eee81083e04440d580802f52b12d3bb9",
            "41cbbacc2fdb49538421a27fdd92197c",
            "f3d2e90564a24c71ad59d56b21d2a433",
            "06ae130c3d33433aa1ebce0db56eac5e",
            "3c1cd0f2d45e41a788aba6ee14cebbbd",
            "5d842b5e5b494c5b89933c3e19bcba38",
            "e2a6711343b64a38ad834c03a1457ae6",
            "31bc500b6ab044ab8161a64a6507adbb",
            "510a523428dd480698f7ea5c596fe35c",
            "13ca8469238d4524a735801d21bc4c65",
            "a6d7ee90a6434dceaa4ebc50288f9ccf",
            "ce4f1405c09648978689b19e54a0d40a",
            "150d80dcea0441d58f6b3dc3da79b62b",
            "2304f8e13d494863b5ac6e2c27f14dd4",
            "f1349aa968e248fe9cd1ded080d31ca8",
            "8392dca438524da9bc6b066e27f7ee6b",
            "af412cc4d392441c8dde1a5ba0f5cc35",
            "0cc364b6b86d44129a5bf967da4e44f3",
            "65cfe6bcba6544b8840349b31722d5df",
            "2aa5ee4f4f704a649acc7d276b1b6984",
            "609f47ebb7364339a23ac69adadb83c2",
            "2f6fdf8a23c34eff855b634c317b7f00",
            "1c77e162208044ceb562e1f6f0a590d2",
            "5c0775c1e4ff48aaad43f695ce11f504",
            "e0c0315c5f7b44c09e3afb0e84faa8bb",
            "58245ea3c25042fdaf6794575a2c7e22",
            "b8ef8d776b88442bac05a97d215e1acb",
            "ead2d62eb47e43a9918c2158d7dbd0d8",
            "e5ac26341ce4443dbe4e257e4b42f9cb",
            "fff61866cb4f4e93aab0f6cb7f63e1f3",
            "34239b4018834752b046461fcd529ce5",
            "f01afc55b65349149882cc0d13d5ef01",
            "ac8b267c66f34a59bed9e527b842e77f",
            "401ceb8fe22d45baab721de5923f4dbd",
            "1d69c525a5fb4e1983ed45f28e6fc2ce",
            "ea31d72b4b2b4e8c9b4ec733598bba51",
            "610ec0a6e0ca4890a36dbb41f39f25c9",
            "ea28eb4900d741dd9d4dabc8c7c7b408",
            "74ac59317bef43469e34d51f4c8c6ea5",
            "35d64ad1f44c4f4e82c14bce34c73750",
            "ef18194e8a9440e8b9ae388930d17f02",
            "018678cee4c744b7804d4b6e9b81ae7e",
            "259988b9b3e34b25b4503418ae98e125",
            "0aea70b3c2fc49d480e349de8ea1f340",
            "6500501cc6384429bf70f4cbdb06ed74",
            "2ef9746b0cf840d7b9646c43afb9f190",
            "fae90e97e922450a99c092eeb61e9722",
            "c7e343b0512a4338931430df4f0dd3f7",
            "e731ad9aa6cd4e7dba0f3003f1638751",
            "b5e184c5dfb14a13ac4de3dee1c23086",
            "c59798a607e944f6b03bc6f09fbbdf6b",
            "9ada42fd9cfc4d8d9d9764b87fc9cf17",
            "adf98e7e76ca49b3872d8bbc92794e50",
            "7062c1615f574525affd9d028344a10a",
            "72910fa789a64e53ae539be5c4dbc410",
            "04d808d194ab43cc81c4ec79bc9b83fd",
            "b273bc59e9a44cc1a273441577cd6428"
          ]
        },
        "id": "xo4cgVT11DzL",
        "outputId": "0bd4e373-6e62-4ede-e85e-2e0127812e46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80cc701bc5eb4ac9a92381f21b88254c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c7742bbb2024b70bd6cd93c74ddb698",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "006ff79eaec7426d98ce092dacf8c075",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88d1ac44a85b423dbe270d73fe645194",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d521069967e345aeb003144142a45801",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89c65cd249c9418092e101ce349d2379",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3d2e90564a24c71ad59d56b21d2a433",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2304f8e13d494863b5ac6e2c27f14dd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0c0315c5f7b44c09e3afb0e84faa8bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea31d72b4b2b4e8c9b4ec733598bba51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fae90e97e922450a99c092eeb61e9722",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "embeddings = model.encode(texts)\n",
        "embedding_array = np.array(embeddings).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuwckNpM2vqs",
        "outputId": "c3e49939-8380-4b59-c743-7d8672b5a94f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQLowGhx1tKi"
      },
      "outputs": [],
      "source": [
        "dim = embedding_array.shape[1]\n",
        "idx = faiss.IndexFlatL2(dim)\n",
        "\n",
        "idx.add(embedding_array)\n",
        "faiss.write_index(idx, \"/content/drive/MyDrive/vedas-rag/embeddings/rigveda_book1.index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyZ7YY5C2tw8",
        "outputId": "33ea8863-143e-446f-e3c4-650ead84fa27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ HYMN LXX. Agni.\n",
            "HYMN LXX. Agni.\n",
            "1. MAY we, the pious, win much food by prayer, may Agni with fair light pervade each act,— He the observer of the heavenly laws of Gods, and of the race of mortal man. He who is germ of waters, germ of woods, germ of all things that move not and that move,— To him even in the rock an \n",
            "---\n",
            "→ HYMN XII. Agni.\n",
            "HYMN XII. Agni.\n",
            "WE choose Agni the messenger, the herald, master of all wealth, Well skilled in this our sacrifice. With callings ever they invoke Agni, Agni, Lord of the House, Oblation-bearer, much beloved. Bring the Gods hither, Agni, born for him who strews the sacred grass: Thou art our herald, \n",
            "---\n",
            "→ HYMN I. Agni.\n",
            "HYMN I. Agni.\n",
            "I Laud Agni, the chosen Priest, God, minister of sacrifice, The hotar, lavishest of wealth. Worthy is Agni to be praised by living as by ancient seers. He shall bring hitherward the Gods. Through Agni man obtaineth wealth, yea, plenty waxing day by day, Most rich in heroes, glorious. A \n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# testing retrieval\n",
        "query = \"Who is Agni?\"\n",
        "q_v = model.encode([query]).astype('float32')\n",
        "D, I = idx.search(q_v, k=3)\n",
        "for idx in I[0]:\n",
        "    print(f\"→ {metadatas[idx]['title']}\")\n",
        "    print(texts[idx][:300], \"\\n---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1GtORWpZuve8kijxgYfBZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}